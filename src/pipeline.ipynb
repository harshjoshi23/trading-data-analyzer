{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic for Close: -0.8409265810431817\n",
      "p-value for Close: 0.8068036934645146\n",
      "Series 'Close' is non-stationary, applying differencing.\n",
      "\n",
      "Preparing data for LSTM...\n",
      "Using device: cuda\n",
      "Training LSTM model...\n",
      "Epoch [5/20], Loss: 0.017051\n",
      "Epoch [10/20], Loss: 0.013176\n",
      "Epoch [15/20], Loss: 0.012339\n",
      "Epoch [20/20], Loss: 0.012301\n",
      "Mean Squared Error on Test Set: 0.0381\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load the data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load stock market data from a CSV file.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%Y', errors='coerce')\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to make data stationary\n",
    "def make_stationary(data, column='Close'):\n",
    "    \"\"\"Check stationarity and apply differencing if needed.\"\"\"\n",
    "    # Ensure data is finite\n",
    "    if not np.isfinite(data[column]).all():\n",
    "        print(f\"Warning: '{column}' contains non-finite values. Cleaning data...\")\n",
    "        data[column] = data[column].replace([np.inf, -np.inf], np.NaN).fillna(method='ffill')\n",
    "        if data[column].isna().any():\n",
    "            data[column] = data[column].fillna(method='bfill')  # Backup fill\n",
    "    result = adfuller(data[column].dropna())\n",
    "    print(f'ADF Statistic for {column}: {result[0]}')\n",
    "    print(f'p-value for {column}: {result[1]}')\n",
    "    if result[1] > 0.05:\n",
    "        print(f\"Series '{column}' is non-stationary, applying differencing.\")\n",
    "        return data[column].diff().dropna()\n",
    "    print(f\"Series '{column}' is stationary.\")\n",
    "    return data[column]\n",
    "\n",
    "# Load and preprocess data\n",
    "data = load_data('../data/Stock_Market_Data.csv')\n",
    "if data is not None:\n",
    "    # Select data for one stock (e.g., '01.Bank')\n",
    "    stock_name = '01.Bank'\n",
    "    data_stock = data[data['Name'] == stock_name].copy()\n",
    "    if data_stock.empty:\n",
    "        print(f\"Error: No data found for stock '{stock_name}'. Check stock names with data['Name'].unique().\")\n",
    "    else:\n",
    "        data_stock.set_index('Date', inplace=True)\n",
    "        data_stock = data_stock.drop(columns=['Name'])\n",
    "        \n",
    "        # Handle missing or infinite values and ensure daily frequency\n",
    "        data_stock = data_stock.replace([np.inf, -np.inf], np.NaN)\n",
    "        data_stock = data_stock.asfreq('D', method='ffill')\n",
    "        \n",
    "        # Make the Close price stationary\n",
    "        stationary_close = make_stationary(data_stock, 'Close')\n",
    "        if stationary_close is None or len(stationary_close) == 0:\n",
    "            print(\"Error: Stationary data is empty after processing.\")\n",
    "        else:\n",
    "            # Prepare data for LSTM\n",
    "            print(\"\\nPreparing data for LSTM...\")\n",
    "            scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_data = scaler.fit_transform(stationary_close.values[:, None])\n",
    "\n",
    "            # Create sequences\n",
    "            def create_sequences(data, seq_length=60):\n",
    "                \"\"\"Create input-output sequences for LSTM.\"\"\"\n",
    "                X, y = [], []\n",
    "                for i in range(len(data) - seq_length):\n",
    "                    X.append(data[i:i + seq_length])\n",
    "                    y.append(data[i + seq_length])\n",
    "                return np.array(X), np.array(y)\n",
    "\n",
    "            seq_length = 60\n",
    "            X, y = create_sequences(scaled_data)\n",
    "            if len(X) == 0:\n",
    "                print(f\"Error: Not enough data points ({len(scaled_data)}) for sequence length {seq_length}.\")\n",
    "            else:\n",
    "                # Split into train and test sets\n",
    "                train_size = int(len(X) * 0.8)\n",
    "                X_train, X_test = X[:train_size], X[train_size:]\n",
    "                y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "                # Convert to PyTorch tensors\n",
    "                X_train = torch.Tensor(X_train)\n",
    "                y_train = torch.Tensor(y_train)\n",
    "                X_test = torch.Tensor(X_test)\n",
    "                y_test = torch.Tensor(y_test)\n",
    "\n",
    "                # Define LSTM model\n",
    "                class LSTMModel(nn.Module):\n",
    "                    def __init__(self, input_size=1, hidden_size=50, num_layers=2):\n",
    "                        super(LSTMModel, self).__init__()\n",
    "                        self.hidden_size = hidden_size\n",
    "                        self.num_layers = num_layers\n",
    "                        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "                        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "                    def forward(self, x):\n",
    "                        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "                        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "                        out, _ = self.lstm(x, (h0, c0))\n",
    "                        out = self.fc(out[:, -1, :])\n",
    "                        return out\n",
    "\n",
    "                # Set device\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                print(f\"Using device: {device}\")\n",
    "\n",
    "                # Initialize model, loss, and optimizer\n",
    "                model = LSTMModel(input_size=1, hidden_size=50, num_layers=2).to(device)\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Create DataLoader\n",
    "                batch_size = 32\n",
    "                train_dataset = TensorDataset(X_train, y_train)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "                # Train the model\n",
    "                num_epocs = 20\n",
    "                print(\"Training LSTM model...\")\n",
    "                for epoch in range(num_epocs):\n",
    "                    model.train()\n",
    "                    total_loss = 0\n",
    "                    for batch_X, batch_y in train_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item()\n",
    "                    avg_loss = total_loss / len(train_loader)\n",
    "                    if (epoch + 1) % 5 == 0:\n",
    "                        print(f'Epoch [{epoch+1}/{num_epocs}], Loss: {avg_loss:.6f}')\n",
    "\n",
    "                # Evaluate the model\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_test = X_test.to(device)\n",
    "                    predictions = model(X_test).cpu().numpy()\n",
    "                    predictions = scaler.inverse_transform(predictions)\n",
    "                    y_test_inv = scaler.inverse_transform(y_test.cpu().numpy())\n",
    "\n",
    "                # Calculate MSE\n",
    "                mse = np.mean((y_test_inv - predictions) ** 2)\n",
    "                print(f'Mean Squared Error on Test Set: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
